{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838c8d74",
   "metadata": {},
   "source": [
    "# In-class activity: Making your own college rankings\n",
    "\n",
    "Cathy O'Neil's chapter, \"Arms Race,\" from _Weapons of Math Destruction_ concludes with a proposed solution for the data manipulation that followed the rise of the U.S. News and World Report college rankings: an [open data portal from the U.S Department of Education](https://collegescorecard.ed.gov/).\n",
    "\n",
    "You've had a chance to look at that portal -- now, you can explore some of the [data](https://collegescorecard.ed.gov/data) yourself, and build your own college ranking model.\n",
    "\n",
    "#### Special Note: Organization of this notebook\n",
    "This time, I've included a clean version up top, where you can work on the problems on your own, and the solutions down at the bottom, if you want to peek ahead to some potential ways to do each step.\n",
    "\n",
    "I _highly encourage_ you to try it on your own first without peeking!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defed00",
   "metadata": {},
   "source": [
    "## Part 1: Load in the data and look at the data dictionary\n",
    "\n",
    "As we saw, the full institution-level dataset from the US Department of Education has more than 6,000 different features in it! I've made a condensed version of it that only has ~115 different features/variables. This data file is available to download from Canvas called `\"college_scorecard_2022.csv\"`.\n",
    "\n",
    "I've also provided a [condensed version of the *data dictionary*](https://docs.google.com/spreadsheets/d/1LjTVjLoXnD4OTKhT7Mw7lWuCvvKqhevZ4rywVfeLioQ/edit?usp=sharing) that explains what features/variables are and what kinds of values they contain.\n",
    "\n",
    "### Step 1. Load the data file into this notebook and examine it.\n",
    "* What do you notice?\n",
    "* How many rows and how many columns does it have?\n",
    "* Which columns are numeric and which are not?\n",
    "* For the numeric values, what ranges do they have?\n",
    "\n",
    "### Step 2. Peruse the simplified [data dictionary](https://docs.google.com/spreadsheets/d/1LjTVjLoXnD4OTKhT7Mw7lWuCvvKqhevZ4rywVfeLioQ/edit?usp=sharing) (which is in a Google Sheet).\n",
    "* How is it organized?\n",
    "* What information is relevant to you as you are making sense of this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b611248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Import necessary packages\n",
    "\n",
    "# Read in data file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e63d9",
   "metadata": {},
   "source": [
    "### Step 3. What are some basic ways you can filter and sort this data to look at some colleges you may be intersted in?\n",
    "\n",
    "For example, Whitman is a small liberal arts college, which means it has a \"Carnegie Classification--basic\" (CCBASIC) value of 21. You might filter this data set to look at liberal arts colleges.\n",
    "\n",
    "Or, Historically Black Colleges and Universities (HBCUs) are indicated in the HBCU column with either a 0 or a 1. You might filter this data set to look at HBCUs.\n",
    "\n",
    "What are some other interesting ways you might filter this dataset?\n",
    "\n",
    "As you are doing this, make sure to consult the data dictionary to see what the column names mean.\n",
    "\n",
    "Pick a subset of colleges you want to focus on (i.e. HBCUs, liberal arts colleges, colleges in the Pacific Northwest, public universities, etc.) and make a new data frame with those colleges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103c4896",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/md/qwf7kdt11_dcxx0gqqb7xrm40000gq/T/ipykernel_31080/1269503922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Note: By default, Jupyter only shows 20 columns at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# You can override this by using the following line:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# You can also get a list of all of the columns with the following line:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Note: By default, Jupyter only shows 20 columns at a time\n",
    "# You can override this by using the following line:\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# You can also get a list of all of the columns with the following line:\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460136c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Select a subset of the colleges (however you like) and make a new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339eac5",
   "metadata": {},
   "source": [
    "## Part 2: Making your own college ranking\n",
    "\n",
    "What features/columns are important to _you_ in selecting a college? (Or, since you have already gone through this process, you might think about a sibling or a friend who is thinking about what college they might want to attend.)\n",
    "\n",
    "### Step 4. Pick a subset of the columns (at least 5, but no more than 10) that you want to include in your custom ranking\n",
    "\n",
    "Using the data dictionary, highlight the features / columns that you want to include in your custom ranking. (Remember that column D in the data dictionary, VARIABLE NAME, is the one that has the column name in your data frame.)\n",
    "\n",
    "Make a new data frame that just has the institution name and these 5-10 columns that you are interested in.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Select a subset of columns and make a new data frame\n",
    "\n",
    "# Hint: Remember that you can select many columns at once using a list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18691bb",
   "metadata": {},
   "source": [
    "### Step 5: Normalizing the data values\n",
    "\n",
    "Look at the columns that you have picked. Is there a way to add them all together to come up with a single score?\n",
    "\n",
    "To do this, we have to think about:\n",
    "* What types of data do they contain?\n",
    "* Are some numeric? For the numeric values, what range do they have (max and min)?\n",
    "* Are some categorial or quantitative?\n",
    "\n",
    "Figure out a way to turn each column into a number on a shared scale (i.e. 0 to 1, or -1 to 1). This process is called **normalization**.\n",
    "\n",
    "As you do this, think about what values you are imbuing into the data. Are you assuming that some values are preferable to others?\n",
    "\n",
    "For example, how might we normalize the values for \"Instructional expenditures per full-time equivalent student\" (INEXPFTE) for liberal arts colleges?\n",
    "\n",
    "First, we would look at the range of values in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generalized way to do this is what is called min-max normalization:\n",
    "\n",
    "# SCALED VALUE = (OLD VALUE - MIN) / (MAX - MIN)\n",
    "\n",
    "# Or, to put it in terms of dataframes:\n",
    "\n",
    "# df[scaled_column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "\n",
    "# You can also write a for loop to iterate over all the columns in your data frame to do this!\n",
    "# But, depending on the columns you chose, this might not work for all of them.\n",
    "\n",
    "# More on min-max normalization here: https://towardsdatascience.com/everything-you-need-to-know-about-min-max-normalization-in-python-b79592732b79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172a8323",
   "metadata": {},
   "source": [
    "## Part 4: Adding the columns together & weighting them\n",
    "\n",
    "Now that you have normalized your columns, you can add them all together.\n",
    "\n",
    "### Step 6: Create a new column that sums the other columns. \n",
    "\n",
    "This new column is your rank.\n",
    "\n",
    "Which colleges have the highest overall scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8304f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Create a new column that adds the normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the result?\n",
    "\n",
    "# Display the ranking by using .sort_values()\n",
    "\n",
    "# You can also use .rank() to add in a ranking\n",
    "# See: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d838d2c",
   "metadata": {},
   "source": [
    "### Step 7: Create *weights* for each column\n",
    "\n",
    "Right now, each column as an equal weight. That is, all of the 10 (or 20) features you picked contribute the same amount to the overall score. But that might not be what you want.\n",
    "\n",
    "Think about how you might weigh each column on a value between 0 and 1. If something has a weight of 1, it is really important. If it has a weight of 0, it is not important at all (and in fact won't be included in the model). Or, if you have 5 columns, you might rank them and give each one a weight between 1 and 5.\n",
    "\n",
    "Are there any columns that should have a negative weight (i.e., it should detract from the overall score)?\n",
    "\n",
    "_For folks taking machine learning, this is how many ML algorithms work!_ The difference is that you use a mathematical model to determine the weights, instead of a human's preferences.\n",
    "\n",
    "Come up with weights for each of the columns you picked. Now, calculate a new total using these weights.\n",
    "\n",
    "How has the ranking changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# You can do this by writing out a formula\n",
    "\n",
    "# You might also make a dictionary of weights and use that to calculate the weighted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the new rankings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ceba04",
   "metadata": {},
   "source": [
    "_______\n",
    "### Professor Wirfs-Brock's sample solution\n",
    "\n",
    "Only peek at this if you need to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load in the .csv as a data frame\n",
    "df = pd.read_csv(\"college_scorecard_2022.csv\")\n",
    "\n",
    "# Examine your data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, say we are focusing on a ranking for liberal arts colleges\n",
    "# We might make a liberal arts data frame\n",
    "\n",
    "liberal_arts = df[df[\"CCBASIC\"] == 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95972375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to focus on HBCUs:\n",
    "\n",
    "HBCUs = df[df[\"HBCU\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d36b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking a subset of columns:\n",
    "\n",
    "# For example, let's focus on liberal arts colleges using the following criteria:\n",
    "\n",
    "# Admission rate - ADM_RATE\n",
    "# Percentage of degrees awarded in Computer And Information Sciences And Support Services. - PCIP11\n",
    "# Percentage of degrees awarded in English Language And Literature/Letters. - PCIP23\n",
    "# Average cost of attendance (academic year institutions) - COSTT4_A\n",
    "# Median earnings of students working and not enrolled 10 years after entry - MD_EARN_WNE_P10\n",
    "# Instructional expenditures per full-time equivalent student - INEXPFTE\n",
    "\n",
    "liberal_arts_ranking = liberal_arts[[\"INSTNM\",\"ADM_RATE\",\"PCIP11\",\"PCIP23\",\"COSTT4_A\",\"MD_EARN_WNE_P10\",\"INEXPFTE\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f40025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the values\n",
    "\n",
    "# We might first use .describe() to look at the range of values:\n",
    "liberal_arts_ranking[\"INEXPFTE\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbecc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can scale the max, 48373 to 1, and the min, 1709, to 0.\n",
    "\n",
    "# The first way we might do this is just by calculating a new column using the min-max-scaling-method:\n",
    "# SCALED VALUE = (OLD VALUE - MIN) / (MAX - MIN)\n",
    "\n",
    "liberal_arts_ranking[\"INEXPFTE_s\"] = (liberal_arts_ranking[\"INEXPFTE\"] - 1709)/(48373-1709)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the new distribution,\n",
    "# notice how the max is 1 and the min is 0\n",
    "liberal_arts_ranking[\"INEXPFTE_s\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fb695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here's how we might normalize ALL the columns at once:\n",
    "\n",
    "# here's where we make a new dataframe with just the columns are are interested in\n",
    "liberal_arts_ranking = liberal_arts[[\"INSTNM\",\"ADM_RATE\",\"PCIP11\",\"PCIP23\",\"COSTT4_A\",\"MD_EARN_WNE_P10\",\"INEXPFTE\" ]]\n",
    "\n",
    "# make a copy the data frame\n",
    "liberal_arts_normalized = liberal_arts_ranking.copy()\n",
    "\n",
    "# list of columns we want to normalize\n",
    "to_normalize = [\"ADM_RATE\",\"PCIP11\",\"PCIP23\",\"COSTT4_A\",\"MD_EARN_WNE_P10\",\"INEXPFTE\"]\n",
    "\n",
    "# apply normalization techniques\n",
    "for column in to_normalize:\n",
    "    liberal_arts_normalized[column] = (liberal_arts_normalized[column] - liberal_arts_normalized[column].min()) / (liberal_arts_normalized[column].max() - liberal_arts_normalized[column].min())\n",
    "\n",
    "# view normalized data\n",
    "# Note how all the maxes are 1 and all the mins are 0\n",
    "liberal_arts_normalized.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fdb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the total score:\n",
    "\n",
    "# we can use the list of columns we care about, to_normalize, to do a sum\n",
    "liberal_arts_normalized[\"score\"] = liberal_arts_normalized[to_normalize].sum(axis=1)\n",
    "\n",
    "liberal_arts_normalized.sort_values(\"score\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can make a new column with the rank as well using the .rank method\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html\n",
    "\n",
    "liberal_arts_normalized[\"rank\"] = liberal_arts_normalized[\"score\"].rank(ascending=False)\n",
    "\n",
    "liberal_arts_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And where is Whitman?\n",
    "liberal_arts_normalized[liberal_arts_normalized[\"INSTNM\"] == \"Whitman College\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88604c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding in weights\n",
    "\n",
    "# How might we do the weighting? You could write out a long formula -- that is fine!\n",
    "# But we can also expedite it with a dictionary.\n",
    "# Here, our keys are the column names, and our values are the weights.\n",
    "# For example:\n",
    "\n",
    "weights = {\"ADM_RATE\":7,\"PCIP11\":1,\"PCIP23\":2,\"COSTT4_A\":3,\"MD_EARN_WNE_P10\":4,\"INEXPFTE\":6}\n",
    "\n",
    "# Now we can make a new column using the weights\n",
    "liberal_arts_normalized['weighted_score'] = sum([liberal_arts_normalized[key] * weights[key] for key in weights.keys()])\n",
    "\n",
    "# view weighted data\n",
    "liberal_arts_normalized.sort_values(\"weighted_score\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now where is Whitman?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
