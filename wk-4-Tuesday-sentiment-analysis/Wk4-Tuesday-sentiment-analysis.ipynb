{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d4c8ff",
   "metadata": {},
   "source": [
    "# In-Class Activity: Sentiment Analysis\n",
    "\n",
    "_September 19, 2023_\n",
    "\n",
    "In \"Data Reimagined,\" you read about how researchers have analyzed speech and written text to draw conclusions about how people interact with each other. These kinds of analyses are part of a data science sub-field called [natural language processling, or NLP](https://en.wikipedia.org/wiki/Natural_language_processing).\n",
    "\n",
    "In this activity, we'll do a simple NLP project using a method called [_sentiment analysis_](https://en.wikipedia.org/wiki/Sentiment_analysis), which looks at how many positive and negative words are used in a piece of text.\n",
    "\n",
    "This activity is adapted from:\n",
    "\n",
    "Zoë Wilkinson Saldaña, [\"Sentiment Analysis for Exploratory Data Analysis,\"](https://programminghistorian.org/en/lessons/sentiment-analysis) Programming Historian 7 (2018), https://doi.org/10.46430/phen0079."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60fa98",
   "metadata": {},
   "source": [
    "### Getting started: Importing packages\n",
    "\n",
    "We'll use a new package this time, nltk, as well as a couple of other features. Run the cells below to install everything you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb10511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f7a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using a package called nltk, or the Natural Language Tool Kit\n",
    "# If you are using Anaconda, it should already be installed and you just need to import it\n",
    "import nltk\n",
    "\n",
    "# This is the sentiment analyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# If you run this block of code and get an error, you may need to install or update nltk\n",
    "# See: https://www.nltk.org/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c37a3",
   "metadata": {},
   "source": [
    "We will be using a method called VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis ([GitHub page here](https://github.com/cjhutto/vaderSentiment#about-the-scoring)), which essentially looks at each individual word in a piece of text and marks it as either negative, positive, or neutral.\n",
    "\n",
    "If you are curious, the paper that introduces this method (and goes into a great bit of detail!) is here:\n",
    "\n",
    "[Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.](https://ojs.aaai.org/index.php/ICWSM/article/view/14550/14399)\n",
    "\n",
    "The VADER lexicon has ~7500 words in it, and you can [view it here.](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt)\n",
    "\n",
    "**Some negative words**: awful, avoiding, boredom, ):<\n",
    "\n",
    "**Some positive words**: awesome, boldest, clever, :)\n",
    "\n",
    "**Some neutral words**: aboard, amorphously\n",
    "\n",
    "The code below gets the VADER dataset, as well as a tokenizer (we'll get to it -- it turns a big block of text into smaller pieces, in our case, sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df28c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/wirfsbrj/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/wirfsbrj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the VADER dataset\n",
    "nltk.download('vader_lexicon')\n",
    "# This is the tokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f09e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a sample sentence one...\n",
    "aSentence = \"Happy families are all alike; every unhappy family is unhappy in its own way.\"\n",
    "bSentence = \"I love data science :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ac2ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates a sentiment intensity object (which we'll call sid)\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f962a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we get the sentiment scores for that sentence\n",
    "scores = sid.polarity_scores(bSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04c4b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.217, 'pos': 0.783, 'compound': 0.802}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ddb120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: 0.802, neg: 0.0, neu: 0.217, pos: 0.783, "
     ]
    }
   ],
   "source": [
    "# The sentiment scores are in the form of a dictionary\n",
    "# This prints them in a nice format\n",
    "for key in sorted(scores):\n",
    "    print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db62c4a8",
   "metadata": {},
   "source": [
    "How do we read these scores?\n",
    "\n",
    "* _compound_ is the overall sentiment for the piece of text. It is a number between -1 and 1, with -1 being the most negative possible, and 1 being the most positive possible. This a score of -0.2263 is only slightly negative.\n",
    "\n",
    "* _neg_, _neu_, and _pos_ tell us the proportion of words in this piece of text that are negative, neutral or positive. In the sentence above, 27.6% of the words are negative, 54.2% are neutral, and 18.2% are positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e5448",
   "metadata": {},
   "source": [
    "### Now you try! Use the method above to find the sentiment scores of some different sentences or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6562b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.303, 'pos': 0.697, 'compound': 0.3182}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "scores = sid.polarity_scores(\"I feel curious\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c9d52d",
   "metadata": {},
   "source": [
    "Share with the person next to you some of the interesting things you found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd131ed1",
   "metadata": {},
   "source": [
    "### Let's read in a bigger text file -- the chapter you read and annotated\n",
    "\n",
    "The chapter is in a file called 'data-reimagined.txt' -- let's take a quick look at it in a text editor first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d90e369d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data-reimagined.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This code opens up the text file and saves it as variable called chapter\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata-reimagined.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     chapter \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data-reimagined.txt'"
     ]
    }
   ],
   "source": [
    "# This code opens up the text file and saves it as variable called chapter\n",
    "with open('data-reimagined.txt') as f:\n",
    "    chapter = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what it looks like\n",
    "print(chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code gets the sentiment scores for the entire chapter (as one block)\n",
    "scores = sid.polarity_scores(chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's print them out\n",
    "for key in sorted(scores):\n",
    "    print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df85f7",
   "metadata": {},
   "source": [
    "What is going on here? Why is the compound score 1, when most of the words are neutral, and positive words are twice as likely as negative ones?\n",
    "\n",
    "It has to do with how VADER calculates compound score -- which is based on the sum of all of the words. As a reminder, here's the equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ced99a",
   "metadata": {},
   "source": [
    "$$\\frac{x}{\\sqrt{x^2+15}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac47bb24",
   "metadata": {},
   "source": [
    "As you get more and more words (x gets larger in our sentiment score formula), the score approaches either 1 or -1! (For more on that, check out [this blog post.](https://medium.com/@piocalderon/vader-sentiment-analysis-explained-f1c4f9101cd9))\n",
    "\n",
    "_(And the lesson here is: Always check how analysis methods you are using actually work!)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6410442d",
   "metadata": {},
   "source": [
    "### Tokenizing: Breaking up a big chunk of text into smaller pieces\n",
    "\n",
    "So, in order to do analysis on this chapter, we'll need to **break it up into sentences.** This is called _tokenization_.\n",
    "\n",
    "We'll use a built in tokenizer in nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ddcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Tokenize the chapter -- and save the tokens as a variable called sentences\n",
    "sentences = tokenizer.tokenize(chapter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine...first print it out\n",
    "# Note that sentences is a list\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef404313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sentences do we have?\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb03ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And pull out a single sentence to look at it\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd9974",
   "metadata": {},
   "source": [
    "One way to analyze this whole chapter is to calculate a sentiment score for each sentence, and then look at the distribution of those. Let's do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of compound (total) scores for each of our sentences\n",
    "compound_scores = []\n",
    "for sentence in sentences:\n",
    "    # This selects the compound score from the dictionary of sentiment scores\n",
    "    compound_scores.append(sid.polarity_scores(sentence)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15617d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's put them in a dataframe\n",
    "# There are many ways to do this, but here's one:\n",
    "# First we \"zip\" the two lists (sentences, compound_scores) into a tuple\n",
    "sentence_sentiment = list(zip(sentences, compound_scores))\n",
    "\n",
    "# Then we create a new data frame, df, and give it the tuple and a list of column names\n",
    "df = pd.DataFrame(sentence_sentiment, columns=['Sentence','Compound Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine it using .describe(), .head(), etc...\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by the 'Compound Score' column to see our range\n",
    "# Lets save it as a new data frame, df_sorted\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df_sorted = df.sort_values('Compound Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most positive sentence\n",
    "# Hint: Use .iloc to select a row, and then select the 'Sentence' column from that row\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the most negative sentence\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2012a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What other sentences might you examine?\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: \n",
    "# Add columns in your data frame for the percent of positive, negative, and neutral words in each sentence\n",
    "# What sentence has the highest proportion of positive words?\n",
    "# What sentence has the highest proportion of negative words?\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2:\n",
    "# Make a plot or plots to visualize the sentiment data for the \"Data Reimagined\" chapter\n",
    "# You might start with a line plot (see notes from last week)\n",
    "# If you want to try something new, check out the histogram: https://matplotlib.org/stable/gallery/statistics/hist.html\n",
    "# Hint: to make a line plot, use .plot(), to make a histogram, use .hist()\n",
    "# You'll also need to import matplotlib using: from matplotlib import pyplot as plt\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3:\n",
    "# Pick another piece of text to analyze.\n",
    "# It could be a paper you wrote, or social media posts, or your annotations on the chapter, or anything...\n",
    "# Perform a basic sentiment analysis on it\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
